{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ploting_decompose.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DefaultaideN/EncodeBoosting/blob/main/ploting_decompose.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEo4pDStbd3z"
      },
      "source": [
        "#!pip install seaborn\n",
        "#!pip install tensorflow\n",
        "#!pip install tf_keras_vis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbZCAxSJbwo9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "323f7389-994f-468a-e172-6400e42880af"
      },
      "source": [
        "#Load some packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(\"Tensorflow Edition:\", tf.__version__)\n",
        "seed = 2020\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "print(\"Packages Loaded!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow Edition: 2.4.0\n",
            "Packages Loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX8vysm6bwrq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03852e2a-c7c6-44b2-ffc9-c62aaaf8d4a4"
      },
      "source": [
        "#inspect GPU\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "n_GPUs = len(physical_devices)\n",
        "print(\"Num_GPUs_Available:\", n_GPUs)\n",
        "if n_GPUs>0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num_GPUs_Available: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pju-xSJtbwut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "420f6e0e-4bfc-4f65-e86b-dfa1083e0715"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jan  9 08:13:28 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    10W /  70W |     10MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ykpnejv5bwxs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6c7f989-e656-41b8-82ec-79c560174252"
      },
      "source": [
        "#load data from Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ93yaUebw6T"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "class encode_booster():\n",
        "  \n",
        "  def __init__(self, model_list, img_process_list, data_path, save_path, name_list):\n",
        "    self.model_list = model_list\n",
        "    self.img_process_list = img_process_list\n",
        "    self.save_path = save_path\n",
        "    self.data_path = data_path\n",
        "    self.name_list = name_list\n",
        "\n",
        "\n",
        "  def load_data(self, part, index, batch_size=16):\n",
        "    single_model = self.model_list[index]\n",
        "    single_process = self.img_process_list[index]\n",
        "    input_shape = single_model.layers[0].input_shape[0][1:3]\n",
        "\n",
        "    image_loader = ImageDataGenerator(preprocessing_function = single_process)\n",
        "    aug_loader = ImageDataGenerator(\n",
        "      preprocessing_function = single_process,\n",
        "      #rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      #width_shift_range=0.2,\n",
        "      #height_shift_range=0.2,\n",
        "      #shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest',\n",
        "      vertical_flip=True,\n",
        "      channel_shift_range=10\n",
        "      )\n",
        "    \n",
        "    if part==0:\n",
        "      print('Trainingset:')\n",
        "      loader = image_loader.flow_from_directory(directory=self.data_path+'train', shuffle=False,\n",
        "                            target_size=input_shape, batch_size=batch_size)\n",
        "    if part==1:\n",
        "      print('Validation dataset:')\n",
        "      loader = image_loader.flow_from_directory(directory=self.data_path+'val', shuffle=False,\n",
        "                            target_size=input_shape, batch_size=batch_size) \n",
        "    if part==2:\n",
        "      print('Testingset:')\n",
        "      loader = image_loader.flow_from_directory(directory= self.data_path+'test', shuffle=False,\n",
        "                            target_size=input_shape, batch_size=16)\n",
        "    \n",
        "    return loader\n",
        "\n",
        "\n",
        "  def print_test(self, index):\n",
        "    single_model = self.model_list[index]\n",
        "    single_process = self.img_process_list[index]\n",
        "    input_shape = single_model.layers[0].input_shape[0][1:3]\n",
        "    image_loader = ImageDataGenerator(preprocessing_function = single_process)\n",
        "\n",
        "    test_loader = image_loader.flow_from_directory(directory= self.data_path+'test', target_size=input_shape, batch_size=16)\n",
        "    print('Testing model_{} ...'.format(index))\n",
        "    results = single_model.evaluate(test_loader)\n",
        "    print('model_{}: test_loss:{:.3f}, test_auc:{:.3f}\\n'.format(index, results[0], results[1]))  \n",
        "\n",
        "\n",
        "  def plot_decompose(self, encode, index, labels, part):\n",
        "    model_name = 'Part '+str(part)+': model_'+str(index)+'_'+self.name_list[index]\n",
        "    fig = plt.figure(index*3+part, figsize=[3*7, 7])\n",
        "    axes = fig.subplots(1, 3)\n",
        "\n",
        "    from sklearn.manifold import TSNE\n",
        "    decomposer_tsne = TSNE(n_components=2)\n",
        "    de_tsne = decomposer_tsne.fit_transform(encode)\n",
        "    scatter = axes[0].scatter(x=de_tsne[:,0], y=de_tsne[:,1], c=labels)\n",
        "    legend1 = axes[0].legend(*scatter.legend_elements(), loc=\"best\", title=\"Classes\")\n",
        "    axes[0].set_title(model_name+'---Tsne')\n",
        "    axes[0].add_artist(legend1)\n",
        "\n",
        "    from sklearn.manifold import Isomap\n",
        "    decomposer_iso = Isomap(n_components=2, n_neighbors=10)\n",
        "    de_iso = decomposer_iso.fit_transform(encode)\n",
        "    scatter = axes[1].scatter(x=de_iso[:,0], y=de_iso[:,1], c=labels)\n",
        "    legend1 = axes[1].legend(*scatter.legend_elements(), loc=\"best\", title=\"Classes\")\n",
        "    axes[1].set_title(model_name+'---Isomap')\n",
        "    axes[1].add_artist(legend1)\n",
        "\n",
        "    from sklearn.decomposition import PCA\n",
        "    decomposer_pca = PCA(n_components=2)\n",
        "    de_pca = decomposer_pca.fit_transform(encode)\n",
        "    scatter = axes[2].scatter(x=de_pca[:,0], y=de_pca[:,1], c=labels)\n",
        "    legend1 = axes[2].legend(*scatter.legend_elements(), loc=\"best\", title=\"Classes\")\n",
        "    axes[2].set_title(model_name+'---PCA')\n",
        "    axes[2].add_artist(legend1)\n",
        "\n",
        "\n",
        "  def get_decompose(self, index, data_part):\n",
        "    single_model = self.model_list[index]\n",
        "    single_process = self.img_process_list[index]\n",
        "    input_shape = single_model.layers[0].input_shape[0][1:3]\n",
        "    loader = self.load_data(data_part, index)\n",
        "\n",
        "    labels = np.array([])\n",
        "    for step in range(len(loader)):\n",
        "      X, y = loader.next()\n",
        "      labels = np.append(labels, y.argmax(axis=1))\n",
        "    \n",
        "    encoder = keras.Model(inputs=[self.model_list[index].input],\n",
        "              outputs=[self.model_list[index].layers[-2].output])\n",
        "    single_model = encoder\n",
        "    single_process = self.img_process_list[index]\n",
        "    input_shape = single_model.layers[0].input_shape[0][1:3]\n",
        "\n",
        "    model_encode = single_model.predict(loader)\n",
        "    self.plot_decompose(model_encode, index, labels, data_part)\n",
        "\n",
        "    return np.append(model_encode, labels.reshape(-1, 1), axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3EMxcQVgeGI"
      },
      "source": [
        "SAVE_PATH = '/content/drive/My Drive/PAPER/model_trained/'\r\n",
        "DATA_PATH = '/content/drive/My Drive/PAPER/data/'\r\n",
        "NAME_LIST = ['VGG', 'Xcept', 'Efcb5', 'Res50']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7f8kCF8bw87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9b2fd01a-f269-4612-8725-0b3102260c32"
      },
      "source": [
        "'''\n",
        "#downloading model\n",
        "model_VGG19 = keras.applications.vgg19\n",
        "model_XCEP = keras.applications.xception\n",
        "model_EFCb5 = keras.applications.efficientnet\n",
        "model_RES50 = keras.applications.resnet\n",
        "\n",
        "model_list = [model_VGG19, model_XCEP, model_EFCb5, model_RES50]\n",
        "img_process = [model.preprocess_input for model in model_list]\n",
        "model_list = [model_VGG19.VGG19(), model_XCEP.Xception(), model_EFCb5.EfficientNetB5(), model_RES50.ResNet50()]\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#downloading model\\nmodel_VGG19 = keras.applications.vgg19\\nmodel_XCEP = keras.applications.xception\\nmodel_EFCb5 = keras.applications.efficientnet\\nmodel_RES50 = keras.applications.resnet\\n\\nmodel_list = [model_VGG19, model_XCEP, model_EFCb5, model_RES50]\\nimg_process = [model.preprocess_input for model in model_list]\\nmodel_list = [model_VGG19.VGG19(), model_XCEP.Xception(), model_EFCb5.EfficientNetB5(), model_RES50.ResNet50()]\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XS8NnXHYDYl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97a6044e-cc97-4c9b-e825-933c5223a93e"
      },
      "source": [
        "'''\n",
        "#load model\n",
        "model_loaded = []\n",
        "for i in range(4):\n",
        "  model = keras.models.load_model(SAVE_PATH+'model_'+str(i))\n",
        "  model_loaded.append(model)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n#load model\\nmodel_loaded = []\\nfor i in range(4):\\n  model = keras.models.load_model(SAVE_PATH+'model_'+str(i))\\n  model_loaded.append(model)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMY2Ep2Nkb8y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b19fa201-3397-4333-e013-da1b3a84c9a3"
      },
      "source": [
        "'''\r\n",
        "#generating encode\r\n",
        "test_model = encode_booster(model_loaded, img_process, DATA_PATH, SAVE_PATH, NAME_LIST)\r\n",
        "for data_part in range(3):\r\n",
        "  for model_no in range(4):\r\n",
        "    decompose = test_model.get_decompose(model_no, data_part)\r\n",
        "    file_name = SAVE_PATH+'model_'+str(model_no)+'/part'+str(data_part)+'_encode.csv'\r\n",
        "    np.savetxt(file_name, decompose, delimiter=\",\")\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#generating encode\\ntest_model = encode_booster(model_loaded, img_process, DATA_PATH, SAVE_PATH, NAME_LIST)\\nfor data_part in range(3):\\n  for model_no in range(4):\\n    decompose = test_model.get_decompose(model_no, data_part)\\n    file_name = SAVE_PATH+\\'model_\\'+str(model_no)+\\'/part\\'+str(data_part)+\\'_encode.csv\\'\\n    np.savetxt(file_name, decompose, delimiter=\",\")\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pnp25VjYogTL"
      },
      "source": [
        "encoded_list = []\r\n",
        "labels_list = []\r\n",
        "for model_no in range(4):\r\n",
        "  for data_part in range(3):\r\n",
        "    file_name = SAVE_PATH+'model_'+str(model_no)+'/part'+str(data_part)+'_encode.csv'\r\n",
        "    single_encode = np.genfromtxt(file_name, delimiter=',')\r\n",
        "    encoded_list.append(single_encode[:, :-1])\r\n",
        "    labels_list.append(single_encode[:, -1])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2vaAlJaq8te"
      },
      "source": [
        "def plot_encode(encode, index, labels, part):\r\n",
        "  model_name = 'Part '+str(part)+': model_'+str(index)+'_'+NAME_LIST[index]\r\n",
        "  fig = plt.figure(index*3+part, figsize=[3*7, 7])\r\n",
        "  axes = fig.subplots(1, 3)\r\n",
        "\r\n",
        "  from sklearn.manifold import TSNE\r\n",
        "  decomposer_tsne = TSNE(n_components=2)\r\n",
        "  de_tsne = decomposer_tsne.fit_transform(encode)\r\n",
        "  scatter = axes[0].scatter(x=de_tsne[:,0], y=de_tsne[:,1], c=labels)\r\n",
        "  legend1 = axes[0].legend(*scatter.legend_elements(), loc=\"best\", title=\"Classes\")\r\n",
        "  axes[0].set_title(model_name+'---Tsne')\r\n",
        "  axes[0].add_artist(legend1)\r\n",
        "\r\n",
        "  from sklearn.manifold import Isomap\r\n",
        "  decomposer_iso = Isomap(n_components=2, n_neighbors=10)\r\n",
        "  de_iso = decomposer_iso.fit_transform(encode)\r\n",
        "  scatter = axes[1].scatter(x=de_iso[:,0], y=de_iso[:,1], c=labels)\r\n",
        "  legend1 = axes[1].legend(*scatter.legend_elements(), loc=\"best\", title=\"Classes\")\r\n",
        "  axes[1].set_title(model_name+'---Isomap')\r\n",
        "  axes[1].add_artist(legend1)\r\n",
        "\r\n",
        "  from sklearn.decomposition import PCA\r\n",
        "  decomposer_pca = PCA(n_components=2)\r\n",
        "  de_pca = decomposer_pca.fit_transform(encode)\r\n",
        "  scatter = axes[2].scatter(x=de_pca[:,0], y=de_pca[:,1], c=labels)\r\n",
        "  legend1 = axes[2].legend(*scatter.legend_elements(), loc=\"best\", title=\"Classes\")\r\n",
        "  axes[2].set_title(model_name+'---PCA')\r\n",
        "  axes[2].add_artist(legend1)\r\n",
        "  print('Done!')\r\n",
        "\r\n",
        "  file_name = SAVE_PATH+'model_'+str(model_no)+'/part'+str(data_part)\r\n",
        "  np.savetxt(file_name+'_tsne.csv', de_tsne, delimiter=\",\")\r\n",
        "  np.savetxt(file_name+'_iso.csv', de_iso, delimiter=\",\")\r\n",
        "  np.savetxt(file_name+'_pca.csv', de_pca, delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vq4nNu6IVAIc",
        "outputId": "49d47a96-3b64-44d2-b2b8-54f8839f9892"
      },
      "source": [
        "for model_no in range(4):\r\n",
        "  for data_part in range(3):\r\n",
        "    part = data_part\r\n",
        "    index = model_no\r\n",
        "    file_name = SAVE_PATH+'model_'+str(model_no)+'/part'+str(data_part)+'_'\r\n",
        "    model_name = 'Part '+str(part)+': model_'+str(index)+'_'+NAME_LIST[index]\r\n",
        "    fig = plt.figure(index*3+part, figsize=[3*7, 7])\r\n",
        "    axes = fig.subplots(1, 3)\r\n",
        "    labels = labels_list[index*3+part]\r\n",
        "\r\n",
        "    from sklearn.manifold import TSNE\r\n",
        "    de_tsne = np.genfromtxt(file_name+'tsne.csv', delimiter=',')\r\n",
        "    scatter = axes[0].scatter(x=de_tsne[:,0], y=de_tsne[:,1], c=labels)\r\n",
        "    legend1 = axes[0].legend(*scatter.legend_elements(), loc=\"best\", title=\"Classes\")\r\n",
        "    axes[0].set_title(model_name+'---Tsne')\r\n",
        "    axes[0].add_artist(legend1)\r\n",
        "\r\n",
        "    from sklearn.manifold import Isomap\r\n",
        "    de_iso = np.genfromtxt(file_name+'iso.csv', delimiter=',')\r\n",
        "    scatter = axes[1].scatter(x=de_iso[:,0], y=de_iso[:,1], c=labels)\r\n",
        "    legend1 = axes[1].legend(*scatter.legend_elements(), loc=\"best\", title=\"Classes\")\r\n",
        "    axes[1].set_title(model_name+'---Isomap')\r\n",
        "    axes[1].add_artist(legend1)\r\n",
        "\r\n",
        "    from sklearn.decomposition import PCA\r\n",
        "    de_pca = np.genfromtxt(file_name+'pca.csv', delimiter=',')\r\n",
        "    scatter = axes[2].scatter(x=de_pca[:,0], y=de_pca[:,1], c=labels)\r\n",
        "    legend1 = axes[2].legend(*scatter.legend_elements(), loc=\"best\", title=\"Classes\")\r\n",
        "    axes[2].set_title(model_name+'---PCA')\r\n",
        "    axes[2].add_artist(legend1)\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20WhGoukUl0e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyfJoNDOUl3E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwzxIQYFUl5R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}